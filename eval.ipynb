{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, shuffle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ipymarkup import (\n",
    "    show_line_markup as show_markup,\n",
    "    ascii_markup\n",
    ")\n",
    "\n",
    "from nerus.log import log_progress\n",
    "from nerus.utils import (\n",
    "    head,\n",
    "    iter_sents\n",
    ")\n",
    "from nerus.span import select_type_spans\n",
    "from nerus.load import (\n",
    "    load_raw,\n",
    "    load_norm\n",
    ")\n",
    "from nerus.path import join_path\n",
    "from nerus.const import (\n",
    "    NERUS_,\n",
    "    DUMPS_DIR, RAW, JSONL, GZ,\n",
    "    FACTRU, NE5, GAREEV, BSNLP, LENTA,\n",
    "    DEEPPAVLOV, DEEPPAVLOV_BERT, PULLENTI, TEXTERRA, TOMITA, NATASHA, MITIE, ANNOTATORS,\n",
    "    PER, LOC, ORG\n",
    ")\n",
    "from nerus.eval.score import eval_markups\n",
    "from nerus.eval.report import (\n",
    "    report_table,\n",
    "    format_report,\n",
    "    format_github_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    path = join_path(DUMPS_DIR, NERUS_ + name + RAW + JSONL + GZ)\n",
    "    return list(log_progress(load_raw(path), prefix=name))\n",
    "\n",
    "\n",
    "factru = load(FACTRU)\n",
    "gareev = load(GAREEV)\n",
    "ne5 = load(NE5)\n",
    "bsnlp = load(BSNLP)\n",
    "\n",
    "sources = [FACTRU, GAREEV, NE5, BSNLP]\n",
    "datasets = {\n",
    "    FACTRU: factru,\n",
    "    GAREEV: gareev,\n",
    "    NE5: ne5,\n",
    "    BSNLP: bsnlp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etalons = {}\n",
    "for source in sources:\n",
    "    dataset = datasets[source]\n",
    "    etalon = [_.source.adapted for _ in log_progress(dataset, prefix=source)]\n",
    "    etalons[source] = etalon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(source, annotator):\n",
    "    dataset = datasets[source]\n",
    "    etalon = etalons[source]\n",
    "    guess = [_.find(annotator).adapted for _ in dataset]\n",
    "    return eval_markups(guess, etalon)\n",
    "\n",
    "\n",
    "annotators = ANNOTATORS\n",
    "keys = [\n",
    "    (source, annotator)\n",
    "    for annotator in annotators\n",
    "    for source in sources\n",
    "]\n",
    "scores = {_: eval(*_) for _ in log_progress(keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = report_table(scores, sources, annotators)\n",
    "output = format_report(table)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th colspan=\"3\" halign=\"left\">factru</th>\n",
    "      <th colspan=\"3\" halign=\"left\">gareev</th>\n",
    "      <th colspan=\"3\" halign=\"left\">ne5</th>\n",
    "      <th colspan=\"3\" halign=\"left\">bsnlp</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>prec/recall/f1,%</th>\n",
    "      <th>PER</th>\n",
    "      <th>LOC</th>\n",
    "      <th>ORG</th>\n",
    "      <th>PER</th>\n",
    "      <th>LOC</th>\n",
    "      <th>ORG</th>\n",
    "      <th>PER</th>\n",
    "      <th>LOC</th>\n",
    "      <th>ORG</th>\n",
    "      <th>PER</th>\n",
    "      <th>LOC</th>\n",
    "      <th>ORG</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>deeppavlov</th>\n",
    "      <td>86/96/90</td>\n",
    "      <td>85/91/88</td>\n",
    "      <td>72/75/74</td>\n",
    "      <td>90/99/94</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>73/86/79</td>\n",
    "      <td>94/93/94</td>\n",
    "      <td>86/98/91</td>\n",
    "      <td>87/88/88</td>\n",
    "      <td>80/94/86</td>\n",
    "      <td>63/95/76</td>\n",
    "      <td>61/63/62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>deeppavlov_bert</th>\n",
    "      <td>96/97/97</td>\n",
    "      <td>91/93/92</td>\n",
    "      <td>85/79/82</td>\n",
    "      <td>97/99/98</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>88/94/91</td>\n",
    "      <td>99/99/99</td>\n",
    "      <td>98/99/99</td>\n",
    "      <td>98/97/97</td>\n",
    "      <td>93/97/95</td>\n",
    "      <td>73/97/84</td>\n",
    "      <td>79/69/73</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pullenti</th>\n",
    "      <td>95/85/90</td>\n",
    "      <td>86/77/81</td>\n",
    "      <td>68/68/68</td>\n",
    "      <td>91/96/94</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>63/64/63</td>\n",
    "      <td>97/92/95</td>\n",
    "      <td>86/85/86</td>\n",
    "      <td>62/75/68</td>\n",
    "      <td>91/88/89</td>\n",
    "      <td>71/82/76</td>\n",
    "      <td>58/55/56</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>texterra</th>\n",
    "      <td>91/88/90</td>\n",
    "      <td>76/83/80</td>\n",
    "      <td>86/45/59</td>\n",
    "      <td>87/89/88</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>81/42/56</td>\n",
    "      <td>97/83/90</td>\n",
    "      <td>81/73/77</td>\n",
    "      <td>83/46/59</td>\n",
    "      <td>86/85/85</td>\n",
    "      <td>67/92/78</td>\n",
    "      <td>76/42/54</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>tomita</th>\n",
    "      <td>93/92/92</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>90/93/92</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>96/92/94</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>83/92/88</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>-/-/-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>natasha</th>\n",
    "      <td>96/78/86</td>\n",
    "      <td>72/78/75</td>\n",
    "      <td>41/23/29</td>\n",
    "      <td>96/79/87</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>40/30/34</td>\n",
    "      <td>98/75/85</td>\n",
    "      <td>70/71/70</td>\n",
    "      <td>49/32/39</td>\n",
    "      <td>91/76/83</td>\n",
    "      <td>65/88/75</td>\n",
    "      <td>45/28/34</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>mitie</th>\n",
    "      <td>95/82/88</td>\n",
    "      <td>90/81/86</td>\n",
    "      <td>74/41/53</td>\n",
    "      <td>85/84/84</td>\n",
    "      <td>-/-/-</td>\n",
    "      <td>55/38/45</td>\n",
    "      <td>94/62/75</td>\n",
    "      <td>74/56/64</td>\n",
    "      <td>49/38/43</td>\n",
    "      <td>81/66/73</td>\n",
    "      <td>74/86/80</td>\n",
    "      <td>55/49/52</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = format_github_report(table)\n",
    "# html = output.to_html(escape=False)\n",
    "# html = html.replace('border=\"1\"', 'border=\"0\"')\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(iter_sents(factru))\n",
    "seed(5)\n",
    "shuffle(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for sent in sents:\n",
    "#     types = [PER]\n",
    "\n",
    "#     a = sent.source.adapted\n",
    "#     a = list(select_type_spans(a.spans, types))\n",
    "\n",
    "#     b = sent.find(DEEPPAVLOV).adapted\n",
    "#     b = list(select_type_spans(b.spans, types))\n",
    "\n",
    "#     if a == b:\n",
    "#         continue\n",
    "\n",
    "#     show_markup(sent.text, a)\n",
    "#     print('---')\n",
    "#     show_markup(sent.text, b)\n",
    "#     print('---')\n",
    "\n",
    "#     for annotator in [TOMITA, PULLENTI, TEXTERRA, MITIE]:\n",
    "#         markup = sent.find(annotator)\n",
    "#         print(markup.label)\n",
    "#         show_markup(sent.text, markup.adapted.spans)\n",
    "#     print('\\n\\n\\n')\n",
    "\n",
    "#     count += 1\n",
    "#     if count > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = join_path(DUMPS_DIR, NERUS_ + LENTA + JSONL + GZ)\n",
    "lenta = load_norm(path)\n",
    "\n",
    "\n",
    "def format(record):\n",
    "    markup = ascii_markup(record.text, record.spans)\n",
    "    for line in markup.as_ascii:\n",
    "        yield line + '\\n'\n",
    "    yield '\\n\\n'\n",
    "\n",
    "\n",
    "with open('examples/lenta_500.txt', 'w') as file:\n",
    "    for record in head(lenta, 500):\n",
    "        lines = format(record)\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(type, source, text, a, b):\n",
    "    yield '[%s] %s / nerus\\n' % (type, source)\n",
    "    for index, spans in enumerate([a, b]):\n",
    "        if index > 0:\n",
    "            yield '>\\n'\n",
    "        markup = ascii_markup(text, spans)\n",
    "        for line in markup.as_ascii:\n",
    "            yield line + '\\n'\n",
    "    yield '\\n\\n'\n",
    "\n",
    "\n",
    "with open('examples/errors.txt', 'w') as file:\n",
    "    for records in [factru, gareev, ne5]:\n",
    "        sents = list(iter_sents(records))\n",
    "        for type in [PER, LOC, ORG]:\n",
    "            for sent in sents:\n",
    "                a = list(select_type_spans(sent.source.adapted.spans, [type]))\n",
    "                b = list(select_type_spans(sent.find(DEEPPAVLOV_BERT).adapted.spans, [type]))\n",
    "                if a != b:\n",
    "                    lines = format(type, sent.source.label, sent.text, a, b)\n",
    "                    file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
